## 0. Подготовка

***Ставим пакеты:***
```{r}
library(stringr)
library(tidyverse)
```

## 1. Визуализация

Проанализируем данные по времени реакции участников на стимул:

```{r}
#library(ggplot2)
#library(magrittr)
#library(dplyr)

data <-  read.csv('https://raw.githubusercontent.com/astafyevai/mcgurk2017-2018/master/csv/time-bxplt.csv')
data$stimul <- as.factor(data$stimul)
data$time <- as.numeric(as.character(data$time))
ggplot(data, aes(stimul, time))+
  geom_boxplot(aes(group = cut_width(stimul, 1)))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  coord_flip()+
  theme_bw()+
  annotate(geom = "text", x = "ab_vg", y = 35, label = "← здесь мы ожидаем эффект", color = "red")+
  annotate(geom = "text", x = "ab_vg_doubled", y = 35, label = "← здесь мы ожидаем эффект", color = "red")+
  annotate(geom = "text", x = "ap_vk", y = 35, label = "← здесь мы ожидаем эффект", color = "red")+
  annotate(geom = "text", x = "ap_vk_doubled", y = 35, label = "← здесь мы ожидаем эффект", color = "red")+
  labs(x = "стимул", y = "время")
data$time
```
   График содержит диаграммы размаха для каждого отдельно взятого стимула (9 (звонкие одинарные слоги) + 9 (звонкие дублированные слоги) + 9 (глухие одинарные слоги) + 9 (гулхие дублированные слоги) = 36). По оси абсцисс (время) подписаны разброс времени реакции участников, а по оси ординат (стимул) -  названия всех стимулов. Вертикальной чертой на каждой отдельной диаграмме показано среднее время реакции на конкретный стимул. Черные точки означают выбросы.
   Как видно из графика, распределение ответов в основном не превыщает 10 секунд. Сравнив время реакции на одинарные и дублированные стимулы, можно заметить, что в целом на распознавание дублированных слогов уходит больше времени, однако стоит учитывать, что респонденты записывали ответы на листок, и время реакции могло увеличиться по этой причине. Вместе с тем, необходимо учитывать, что PsychoPy работает нестабильно, поэтому некоторые неожиданные результаты могут быть связаны с техническими перебоями. По графику нетрудно заметить, что стимулы, над которыми больше всего думали носители - это ak_vp_doubled, ap_at, ap_vp, ak_vt_doubled (где первая пара букв - аудио стимул с конкретным взрывным, вторая пара букв - видео стимул с конкретным взрывным, наличие/отсутствие doubled - одинарные/двойные повторения соответственно). Те видеозаписи, где мог бы оказаться искомый эффект (ab_vg, ab_vg_doubled, ap_vk, ap_vk_doubled) визуально не отличаются от остальных стимулов.

Посмотрим на ответы респондентов, которые смотрели видеозаписи со звонкими стимулами.

```{r}
df <- read.csv("https://raw.githubusercontent.com/astafyevai/mcgurk2017-2018/master/csv/McGurk.csv")
df[df$voiced == "voiced",] %>%
  count(doubled, audio, video, response, sort = TRUE) %>% 
  ggplot(aes(audio, video, size = n))+
  geom_point(aes(size = n), alpha=0.8, color="pink", show.legend =FALSE) +
  geom_text(aes(label = n), color="black", size = 4) +
  scale_size(range = c(3,20)) +
  facet_grid(doubled~response)+
  theme_bw()+
  labs(x = "audio stimulus",
       y = "video stimulus",
       title = "Voiced results grouped by double/single")
```
График разделен на 4 столбца (ответы респондентов) и 2 строки (одинарные и двойные повторения стимулов). По графику нетрудно заметить, что распределение ответов почти полностью связано с аудио, а не с видео стимулом. Ответов, которые не совпали с аудио и комментариев участника эксперимента практически нет. В ответ "другое" (стобец (-)) попали ответы:
+ когда стимулом служит одинарный слог (1-4 ответы принадлежат одному носителю: мужчина; не знает, что такое эффект МакГурка):
  + ad_vb -> mda
  + ag_vb -> bega
  + ag_vg -> nga
  + ag_vd -> nga
  
  Интересно, что носитель ориентируется на оба стимула сразу: он слышит то, что реально звучит на аудиозаписи, но в его ответах частично содержится характеристика звука с видеозаписи (например, *mda* начинается с губного звука, что явно является влиянием *b*).
  
  Кроме того, был один случай, когда ответ совпал не с аудио, а с видео стимулом.
  + ad_vg -> g (женщина; знает, что такое эффект МакГурка).

+ когда стимулом служит дублированный слог все ответы совпадают с аудио.

В этих экспериментах ожидаемый эффект не проявился.

Сравним это с результатами тех респондентов, которые смотрели видеозаписи с глухими стимулами. 

```{r}
df <- read.csv("McGurk.csv")
df[df$voiced == "unvoiced",] %>%
  count(doubled, audio, video, response, sort = TRUE) %>% 
  ggplot(aes(audio, video, size = n))+
  geom_point(aes(size = n), alpha=0.8, color="pink", show.legend =FALSE) +
  geom_text(aes(label = n), color="black", size = 4) +
  scale_size(range = c(3,20)) +
  facet_grid(doubled~response)+
  theme_bw()+
  labs(x = "audio stimulus",
       y = "video stimulus",
       title = "Unvoiced results grouped by double/single")
```
  Графики сильно отличаются друг от друга. В обоих случаях независимо от того, глухие или звонкие стимулы, несовпадений с аудио больше при одинарном стимуле. Из последнего графика также видно, что  распределение ответов также, как и в первом случае, видимо, связано с аудио, а не видео стимулом, но ответов, не совпавших с аудио значительно больше. 
  
  В ответах носителей, которые проходили эксперимент с глухими стимулами, было намного больше вопросов, комментариев и сомнений. Один носитей
 столбца "-" попали:
+ когда стимулом служит одинарный слог:
  + ap_vp ->	pam (мужчина; не знает, что такое эффект Макгурка)
  + ap_vk ->	pan (мужчина; не знает, что такое эффект Макгурка)
  + ap_vt ->	pan (мужчина; не знает, что такое эффект Макгурка)
  + at_vp -> tam (мужчина; не знает, что такое эффект Макгурка)
  + at_vk -> tan (мужчина; не знает, что такое эффект Макгурка)
  + at_vt -> tam (мужчина; не знает, что такое эффект Макгурка)
  + ap_vt	-> p/k (мужчина; знает, что такое эффект Макгурка)
  + ap_vp -> p/k (мужчина; знает, что такое эффект Макгурка)
  + ap_vt -> k/t	(женщина; знает, что такое эффект Макгурка)

+ когда стимулом служит дублированный слог (ответы принадлежат одному носителю: мужчина, знает, что такое эффект МакГурка):
  + ak_vp ->	kapka
  + at_vp ->	tata/tapta
 
Во всех перечисленных случаях видео стимул каким-то образом влияет на ответ испытуемого. Другие ответы, которые не совпали с аудио стимулом, можно легко прочитать по графику. Ожидаемый эффект проявился 4 раза (2 в эксперименте с глухими одинарными стимулами, 2 - в эксперименте с дублированными глухими стимулами).
Появляется ощущение, что носители отвечают по-разному в зависимости от того, глухие или звонкие стимулы, но эта разница не значительна. 

С помощью тестов проверим, являются ли эти отличия статистически значимы. Перечислим некоторые факты, которые мы хотим доказать:

+ разница в ответах между респондентами, знавшими и не знавшими, что такое эффект МакГурка не является статистически значимой;
+ разница в ответах между респондентами смотревших одинарные и дублированные стимулы не является статистически значимой;
+ разница в ответах между респондентами разного пола не является стастистически значимой;
+ ответы респондентов в нашем эксперименте скорее совпадают с аудио стимулом, а не с видео стимулом.

## 2.1 Зависит ли количество повторяющихся ответов на одни и те же сочетания (audio, video) от знания, что такое эффект МакГурка?

Составим таблицу с уникальными значениями видео стимулов, аудио стимулов, ответов и переменной, кодирующей смотрели ли данный респондент видео стимул, в строках и знание об эффекте в столбцах.

```{r}
my_df <- read.csv("https://raw.githubusercontent.com/astafyevai/mcgurk2017-2018/master/csv/McGurk.csv")
my_df[my_df$voiced == "unvoiced" & my_df$doubled == "doubled",] %>%
  na.omit() %>% 
  count(audio,video,response, knowledge.about.McGurk) %>% 
  spread(key = knowledge.about.McGurk, value = n) %>% 
  mutate(no = ifelse(is.na(no), as.integer(0), no),
         yes = ifelse(is.na(yes), as.integer(0), yes),
         type = paste(audio,video, response)) %>% 
  ungroup() %>% 
  select(type, no, yes) ->
  my_df_UD_mcgurk_test
```
Применим к нашим данным точный тест Фишера.
```{r}
fisher.test(my_df_UD_mcgurk_test[,-1],simulate.p.value=TRUE,B=1e5)
```

+ Во всей совокупности: p-value 0.5017
+ В группе "voiced doubled": p-value 1
+ В группе "voiced single": p-value 0.9795
+ В группе "unvoiced single": p-value 0.6537
+ В группе "unvoiced doubled": p-value 0.9984



## 2.2 Зависит ли количество повторяющихся ответов на одни и те же сочетания (audio, video) от пола?
+ Все в совокупности: p-value 0.3722
+ В группе "unvoiced doubled": p-value 0.9845
+ В группе "voiced doubled": p-value 1
+ В группе "unvoiced single": p-value 0.7018
+ В группе "voiced single": p-value 0.6458

## 2.3 Зависит ли количество повторяющихся ответов на одни и те же сочетания (audio, video) от одинарных/дублированных стимулов?
+ В группе voiced: p-value 1
+ В группе unvoiced: p-value 0.5287
+ Во всей совокупности: p-value 0.9572 

## 2.4 Зависит ли количество повторяющихся ответов на одни и те же сочетания (audio, video) от параметра звонкости/глухости?
+ В группе double: p-value 0.9883
+ В группе single: p-value 0.1598
+ Во всей совокупности: p-value 0.2065

***Везде выский p-value (> 0.05) => все различия не являются статистически значимыми, и у нас нет оснований отбрасывать нулевую гипотезу***

 
