## [Sams, Manninen, Surakka, Helin, Kättö, 1998] 
Sams, M., Manninen, P., Surakka, V., Helin, P., & Kättö, R. (1998). McGurk effect in Finnish syllables, isolated words, and words in sentences: Effects of word meaning and sentence context. Speech Communication, 26(1), 75-87. 

**Subjects**: 65 undergraduate students (62 females, 19-45 years old), most were volunteers 

**Stimuli**: One female talker in front of a white background with her head supported against the wall to avoid movements. She uttered each stimulus several times and the most neutral and clear tokens were selected for the experiment. Informants saw the talker-face on a computer screen as the distance of 60 cm. They were told that the stimuli might be meaningful and meaningless but not about McGurk effect. Subjects had 6 s to answer before the next stimuli started.  

**1.	/pa/ and /ka/**

*	Combines and expected to give rise in most cases to /ta/ or /ka/ perceptions 
*	Acoustical /ka/ was dubbed on to the visual presentation of /ka/ (often perceived as /pka/ or /kpa/) 

**2.	19 different solitary shot natural words, containing phonemes /p/ and /k/ in various vowel context** 

*	Words like /pannu/ were combined with visual perception of  /kannu/ -> expected /tannu/ (non-word) or /kannu/ (meaningful) 
*	Combinations: 
    -	Meaningful (audio) + meaningful (video) -> expected: non-word/video 
    -	Meaningless (audio) + meaningless (video) 

**3.	42 different short natural Finnish words and non-words**, containing phonemes /p/ and /k/ in various vowel context, **presented in different location of three-words sentences.** (the length up to 6 s) **WHITE NOISE OF 53 dB!!!!!** 

*	Combinations: 
   -	Meaningful (audio) + meaningless (video) -> non-word/video 
   -	Meaningless (audio) + meaningless (video) 
   -	Discordant word could be the first, the middle and the last 

**Results (first words and non-word of the sentence):** 

acoustically meaningful sentences: 

* 17% audio 
*	26% video 
*	25% something else 
*	**13% fusion non-word** 
*	19% other non-word 
 auditory and visual non-words: 
*	11% audio 
*	43% video 
*	15% something else 
*	**29% fusion non-word** 
*	2% other non-word 

Differed statictically significantly  
  
**Results (last words and non-word of the sentence):** 

acoustically meaningful sentences: 

* 8% audio 
*	33% video 
*	9% something else 
*	**35% fusion non-word** 
*	15% other non-word 
 auditory and visual non-words: 
*	8% audio  
*	27% video 
*	18% something else 
*	**45% fusion non-word** 
*	2% other non-word 


**Omissions:** (простите, что конспект здесь непонятный, но я просто переписывала, что они дают в статье) 

* occurred in /u/ (2/3) - initial consonants were not perceived in 50% 
*	words started acoustically with /pa/ (10/16) - 7% 
*	/p/ in /i/ context (2/3) - 2.3% 
*	occurred in /e/ with /p/ 
  
 The McGurk effect is very robust - in the experiment it modifies the perception approximately in 90% of the subjects.  
 
## [Dekle, Fowler, Funnell 1992]  

Dekle, D. J., Fowler, C. A., & Funnell, M. G. (1992). Audiovisual integration in perception of real words. Attention, Perception, & Psychophysics, 51(4), 355-362. 

*Trying to explain:* 

+ the motor theory (e.g., Liberman & Mattingly, 1985) 
+ the direct-realist theory (Fowler, 1986; Rosenblum, 1989) 
(in both: listeners to speech are claimed to perceive linguistically significant actions of the vocal tract, which are signaled to different degrees both optically and acoustically.) 
+ the fuzzy-logical theory of speech perception (Massaro, 1987) 
(any cue associated with production of a syllable in experience, and therefore in memory, can serve as information for the syllable. 

> Experiment 1.  

**Subjects**: 33 undergraduated students who participated for course credit in an introductory psychology
course 

**Stimuli**: Five randomized instances of each of nine trial types (types are listed in Table 1)  
![Soundtrack and Video Word Pairs Used in Experiment 1](https://github.com/astafyevai/mcgurk2017-2018/blob/master/dekle_1.jpg)

(The stimuli dubbing was accomplished by filtering one token of each of the nine auditory words at 10 kHz, digitizing them at a sampling rate of 20 kHz) 

*Results* 

- no-view condition - 97% auditory selections, 3% McGurk responses 
- a view condition - 17% audio selections, 79% McGurk responses, 4% video responses 

> Experiment 2. 

**Subjects**: 36 undergraduates from the same population as those who participated in Experiment 1 

**Stimuli**: The same as in Experiment 1. 

*Results* (Both groups were asked 10 circle the word they [saw] the model say)  

- no-audio condition - 69% video selections, 31% McGurk responses 
- with-audio condition - 55% audio selections, 38% McGurk responses, 7% video responses 

[Their conclusion]: McGurk effects occur on nonwords, they occur on words as well; under those same conditions, influences on lipreading (reverse McGurk) are weaker than McGurk effects. 

> Experiment 3.
